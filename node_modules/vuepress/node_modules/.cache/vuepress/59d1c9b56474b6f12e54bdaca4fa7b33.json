{"remainingRequest":"C:\\Users\\Objec\\Desktop\\LearningNote\\node_modules\\vue-loader\\lib\\loaders\\templateLoader.js??vue-loader-options!C:\\Users\\Objec\\Desktop\\LearningNote\\node_modules\\cache-loader\\dist\\cjs.js??ref--1-0!C:\\Users\\Objec\\Desktop\\LearningNote\\node_modules\\vue-loader\\lib\\index.js??ref--1-1!C:\\Users\\Objec\\Desktop\\LearningNote\\node_modules\\vuepress\\lib\\webpack\\markdownLoader.js??ref--1-2!C:\\Users\\Objec\\Desktop\\LearningNote\\docs\\Language\\java\\algorithm.md?vue&type=template&id=4615f64b&","dependencies":[{"path":"C:\\Users\\Objec\\Desktop\\LearningNote\\docs\\Language\\java\\algorithm.md","mtime":1559711629822},{"path":"C:\\Users\\Objec\\Desktop\\LearningNote\\node_modules\\cache-loader\\dist\\cjs.js","mtime":1559711637495},{"path":"C:\\Users\\Objec\\Desktop\\LearningNote\\node_modules\\vue-loader\\lib\\loaders\\templateLoader.js","mtime":1559711718187},{"path":"C:\\Users\\Objec\\Desktop\\LearningNote\\node_modules\\cache-loader\\dist\\cjs.js","mtime":1559711637495},{"path":"C:\\Users\\Objec\\Desktop\\LearningNote\\node_modules\\vue-loader\\lib\\index.js","mtime":1559711718171},{"path":"C:\\Users\\Objec\\Desktop\\LearningNote\\node_modules\\vuepress\\lib\\webpack\\markdownLoader.js","mtime":1559711720027}],"contextDependencies":[],"result":["var render = function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('div',{staticClass:\"content\"},[_vm._m(0),_vm._v(\" \"),_c('h4',{attrs:{\"id\":\"唯一摩尔斯密码词\"}},[_c('a',{staticClass:\"header-anchor\",attrs:{\"href\":\"#唯一摩尔斯密码词\",\"aria-hidden\":\"true\"}},[_vm._v(\"#\")]),_vm._v(\" \"),_c('a',{attrs:{\"href\":\"https://leetcode-cn.com/problems/unique-morse-code-words/\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\"}},[_vm._v(\"唯一摩尔斯密码词\"),_c('OutboundLink')],1)]),_vm._v(\" \"),_c('p',[_vm._v(\"问题分析：遍历单词列表获取每一个字符串，再遍历每个字符串的字符，每个字符与a字符的差值可以作为26个英文字母对应的摩尔斯密码的字符串数组的下标，这样可以找到相应的摩尔斯密码并用stringbuilder存起来提高效率。为了获取最后所有不同单词翻译的数量，说明要去除重复的，hashset不允许重复，底层实现使用hashmap，故使用hashset.add，具体实现代码如下：\")]),_vm._v(\" \"),_vm._m(1)])}\nvar staticRenderFns = [function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('h1',{attrs:{\"id\":\"算法题记录\"}},[_c('a',{staticClass:\"header-anchor\",attrs:{\"href\":\"#算法题记录\",\"aria-hidden\":\"true\"}},[_vm._v(\"#\")]),_vm._v(\" 算法题记录\")])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('div',{staticClass:\"language-java extra-class\"},[_c('pre',{pre:true,attrs:{\"class\":\"language-java\"}},[_c('code',[_c('span',{pre:true,attrs:{\"class\":\"token keyword\"}},[_vm._v(\"class\")]),_vm._v(\" \"),_c('span',{pre:true,attrs:{\"class\":\"token class-name\"}},[_vm._v(\"Solution\")]),_vm._v(\" \"),_c('span',{pre:true,attrs:{\"class\":\"token punctuation\"}},[_vm._v(\"{\")]),_vm._v(\"\\n   \"),_c('span',{pre:true,attrs:{\"class\":\"token class-name\"}},[_vm._v(\"String\")]),_c('span',{pre:true,attrs:{\"class\":\"token punctuation\"}},[_vm._v(\"[\")]),_c('span',{pre:true,attrs:{\"class\":\"token punctuation\"}},[_vm._v(\"]\")]),_vm._v(\" morseArr \"),_c('span',{pre:true,attrs:{\"class\":\"token operator\"}},[_vm._v(\"=\")]),_vm._v(\" \"),_c('span',{pre:true,attrs:{\"class\":\"token punctuation\"}},[_vm._v(\"{\")]),_c('span',{pre:true,attrs:{\"class\":\"token string\"}},[_vm._v(\"\\\".-\\\"\")]),_c('span',{pre:true,attrs:{\"class\":\"token punctuation\"}},[_vm._v(\",\")]),_c('span',{pre:true,attrs:{\"class\":\"token string\"}},[_vm._v(\"\\\"-...\\\"\")]),_c('span',{pre:true,attrs:{\"class\":\"token punctuation\"}},[_vm._v(\",\")]),_c('span',{pre:true,attrs:{\"class\":\"token string\"}},[_vm._v(\"\\\"-.-.\\\"\")]),_c('span',{pre:true,attrs:{\"class\":\"token punctuation\"}},[_vm._v(\",\")]),_c('span',{pre:true,attrs:{\"class\":\"token string\"}},[_vm._v(\"\\\"-..\\\"\")]),_c('span',{pre:true,attrs:{\"class\":\"token punctuation\"}},[_vm._v(\",\")]),_c('span',{pre:true,attrs:{\"class\":\"token string\"}},[_vm._v(\"\\\".\\\"\")]),_c('span',{pre:true,attrs:{\"class\":\"token punctuation\"}},[_vm._v(\",\")]),_c('span',{pre:true,attrs:{\"class\":\"token string\"}},[_vm._v(\"\\\"..-.\\\"\")]),_c('span',{pre:true,attrs:{\"class\":\"token punctuation\"}},[_vm._v(\",\")]),_c('span',{pre:true,attrs:{\"class\":\"token string\"}},[_vm._v(\"\\\"--.\\\"\")]),_c('span',{pre:true,attrs:{\"class\":\"token punctuation\"}},[_vm._v(\",\")]),_c('span',{pre:true,attrs:{\"class\":\"token string\"}},[_vm._v(\"\\\"....\\\"\")]),_c('span',{pre:true,attrs:{\"class\":\"token punctuation\"}},[_vm._v(\",\")]),_c('span',{pre:true,attrs:{\"class\":\"token string\"}},[_vm._v(\"\\\"..\\\"\")]),_c('span',{pre:true,attrs:{\"class\":\"token punctuation\"}},[_vm._v(\",\")]),_c('span',{pre:true,attrs:{\"class\":\"token string\"}},[_vm._v(\"\\\".---\\\"\")]),_c('span',{pre:true,attrs:{\"class\":\"token punctuation\"}},[_vm._v(\",\")]),_c('span',{pre:true,attrs:{\"class\":\"token string\"}},[_vm._v(\"\\\"-.-\\\"\")]),_c('span',{pre:true,attrs:{\"class\":\"token punctuation\"}},[_vm._v(\",\")]),_c('span',{pre:true,attrs:{\"class\":\"token string\"}},[_vm._v(\"\\\".-..\\\"\")]),_c('span',{pre:true,attrs:{\"class\":\"token punctuation\"}},[_vm._v(\",\")]),_c('span',{pre:true,attrs:{\"class\":\"token string\"}},[_vm._v(\"\\\"--\\\"\")]),_c('span',{pre:true,attrs:{\"class\":\"token punctuation\"}},[_vm._v(\",\")]),_c('span',{pre:true,attrs:{\"class\":\"token string\"}},[_vm._v(\"\\\"-.\\\"\")]),_c('span',{pre:true,attrs:{\"class\":\"token punctuation\"}},[_vm._v(\",\")]),_c('span',{pre:true,attrs:{\"class\":\"token string\"}},[_vm._v(\"\\\"---\\\"\")]),_c('span',{pre:true,attrs:{\"class\":\"token punctuation\"}},[_vm._v(\",\")]),_c('span',{pre:true,attrs:{\"class\":\"token string\"}},[_vm._v(\"\\\".--.\\\"\")]),_c('span',{pre:true,attrs:{\"class\":\"token punctuation\"}},[_vm._v(\",\")]),_c('span',{pre:true,attrs:{\"class\":\"token string\"}},[_vm._v(\"\\\"--.-\\\"\")]),_c('span',{pre:true,attrs:{\"class\":\"token punctuation\"}},[_vm._v(\",\")]),_c('span',{pre:true,attrs:{\"class\":\"token string\"}},[_vm._v(\"\\\".-.\\\"\")]),_c('span',{pre:true,attrs:{\"class\":\"token punctuation\"}},[_vm._v(\",\")]),_c('span',{pre:true,attrs:{\"class\":\"token string\"}},[_vm._v(\"\\\"...\\\"\")]),_c('span',{pre:true,attrs:{\"class\":\"token punctuation\"}},[_vm._v(\",\")]),_c('span',{pre:true,attrs:{\"class\":\"token string\"}},[_vm._v(\"\\\"-\\\"\")]),_c('span',{pre:true,attrs:{\"class\":\"token punctuation\"}},[_vm._v(\",\")]),_c('span',{pre:true,attrs:{\"class\":\"token string\"}},[_vm._v(\"\\\"..-\\\"\")]),_c('span',{pre:true,attrs:{\"class\":\"token punctuation\"}},[_vm._v(\",\")]),_c('span',{pre:true,attrs:{\"class\":\"token string\"}},[_vm._v(\"\\\"...-\\\"\")]),_c('span',{pre:true,attrs:{\"class\":\"token punctuation\"}},[_vm._v(\",\")]),_c('span',{pre:true,attrs:{\"class\":\"token string\"}},[_vm._v(\"\\\".--\\\"\")]),_c('span',{pre:true,attrs:{\"class\":\"token punctuation\"}},[_vm._v(\",\")]),_c('span',{pre:true,attrs:{\"class\":\"token string\"}},[_vm._v(\"\\\"-..-\\\"\")]),_c('span',{pre:true,attrs:{\"class\":\"token punctuation\"}},[_vm._v(\",\")]),_c('span',{pre:true,attrs:{\"class\":\"token string\"}},[_vm._v(\"\\\"-.--\\\"\")]),_c('span',{pre:true,attrs:{\"class\":\"token punctuation\"}},[_vm._v(\",\")]),_c('span',{pre:true,attrs:{\"class\":\"token string\"}},[_vm._v(\"\\\"--..\\\"\")]),_c('span',{pre:true,attrs:{\"class\":\"token punctuation\"}},[_vm._v(\"}\")]),_c('span',{pre:true,attrs:{\"class\":\"token punctuation\"}},[_vm._v(\";\")]),_vm._v(\"\\n    \"),_c('span',{pre:true,attrs:{\"class\":\"token class-name\"}},[_vm._v(\"Set\")]),_c('span',{pre:true,attrs:{\"class\":\"token generics\"}},[_c('span',{pre:true,attrs:{\"class\":\"token punctuation\"}},[_vm._v(\"<\")]),_c('span',{pre:true,attrs:{\"class\":\"token class-name\"}},[_vm._v(\"String\")]),_c('span',{pre:true,attrs:{\"class\":\"token punctuation\"}},[_vm._v(\">\")])]),_vm._v(\" moreSet \"),_c('span',{pre:true,attrs:{\"class\":\"token operator\"}},[_vm._v(\"=\")]),_vm._v(\" \"),_c('span',{pre:true,attrs:{\"class\":\"token keyword\"}},[_vm._v(\"new\")]),_vm._v(\" \"),_c('span',{pre:true,attrs:{\"class\":\"token class-name\"}},[_vm._v(\"HashSet\")]),_c('span',{pre:true,attrs:{\"class\":\"token generics\"}},[_c('span',{pre:true,attrs:{\"class\":\"token punctuation\"}},[_vm._v(\"<\")]),_c('span',{pre:true,attrs:{\"class\":\"token punctuation\"}},[_vm._v(\">\")])]),_c('span',{pre:true,attrs:{\"class\":\"token punctuation\"}},[_vm._v(\"(\")]),_c('span',{pre:true,attrs:{\"class\":\"token punctuation\"}},[_vm._v(\")\")]),_c('span',{pre:true,attrs:{\"class\":\"token punctuation\"}},[_vm._v(\";\")]),_vm._v(\"\\n    \"),_c('span',{pre:true,attrs:{\"class\":\"token keyword\"}},[_vm._v(\"public\")]),_vm._v(\" \"),_c('span',{pre:true,attrs:{\"class\":\"token keyword\"}},[_vm._v(\"int\")]),_vm._v(\" \"),_c('span',{pre:true,attrs:{\"class\":\"token function\"}},[_vm._v(\"uniqueMorseRepresentations\")]),_c('span',{pre:true,attrs:{\"class\":\"token punctuation\"}},[_vm._v(\"(\")]),_c('span',{pre:true,attrs:{\"class\":\"token class-name\"}},[_vm._v(\"String\")]),_c('span',{pre:true,attrs:{\"class\":\"token punctuation\"}},[_vm._v(\"[\")]),_c('span',{pre:true,attrs:{\"class\":\"token punctuation\"}},[_vm._v(\"]\")]),_vm._v(\" words\"),_c('span',{pre:true,attrs:{\"class\":\"token punctuation\"}},[_vm._v(\")\")]),_vm._v(\" \"),_c('span',{pre:true,attrs:{\"class\":\"token punctuation\"}},[_vm._v(\"{\")]),_vm._v(\"\\n        \"),_c('span',{pre:true,attrs:{\"class\":\"token keyword\"}},[_vm._v(\"for\")]),_c('span',{pre:true,attrs:{\"class\":\"token punctuation\"}},[_vm._v(\"(\")]),_c('span',{pre:true,attrs:{\"class\":\"token class-name\"}},[_vm._v(\"String\")]),_vm._v(\" eachword\"),_c('span',{pre:true,attrs:{\"class\":\"token operator\"}},[_vm._v(\":\")]),_vm._v(\"words\"),_c('span',{pre:true,attrs:{\"class\":\"token punctuation\"}},[_vm._v(\")\")]),_c('span',{pre:true,attrs:{\"class\":\"token punctuation\"}},[_vm._v(\"{\")]),_vm._v(\"\\n            \"),_c('span',{pre:true,attrs:{\"class\":\"token class-name\"}},[_vm._v(\"StringBuilder\")]),_vm._v(\" sb \"),_c('span',{pre:true,attrs:{\"class\":\"token operator\"}},[_vm._v(\"=\")]),_vm._v(\" \"),_c('span',{pre:true,attrs:{\"class\":\"token keyword\"}},[_vm._v(\"new\")]),_vm._v(\" \"),_c('span',{pre:true,attrs:{\"class\":\"token class-name\"}},[_vm._v(\"StringBuilder\")]),_c('span',{pre:true,attrs:{\"class\":\"token punctuation\"}},[_vm._v(\"(\")]),_c('span',{pre:true,attrs:{\"class\":\"token punctuation\"}},[_vm._v(\")\")]),_c('span',{pre:true,attrs:{\"class\":\"token punctuation\"}},[_vm._v(\";\")]),_vm._v(\"\\n            \"),_c('span',{pre:true,attrs:{\"class\":\"token keyword\"}},[_vm._v(\"for\")]),_c('span',{pre:true,attrs:{\"class\":\"token punctuation\"}},[_vm._v(\"(\")]),_c('span',{pre:true,attrs:{\"class\":\"token keyword\"}},[_vm._v(\"char\")]),_vm._v(\" e\"),_c('span',{pre:true,attrs:{\"class\":\"token operator\"}},[_vm._v(\":\")]),_vm._v(\"eachword\"),_c('span',{pre:true,attrs:{\"class\":\"token punctuation\"}},[_vm._v(\".\")]),_c('span',{pre:true,attrs:{\"class\":\"token function\"}},[_vm._v(\"toCharArray\")]),_c('span',{pre:true,attrs:{\"class\":\"token punctuation\"}},[_vm._v(\"(\")]),_c('span',{pre:true,attrs:{\"class\":\"token punctuation\"}},[_vm._v(\")\")]),_c('span',{pre:true,attrs:{\"class\":\"token punctuation\"}},[_vm._v(\")\")]),_c('span',{pre:true,attrs:{\"class\":\"token punctuation\"}},[_vm._v(\"{\")]),_vm._v(\"\\n                sb\"),_c('span',{pre:true,attrs:{\"class\":\"token punctuation\"}},[_vm._v(\".\")]),_c('span',{pre:true,attrs:{\"class\":\"token function\"}},[_vm._v(\"append\")]),_c('span',{pre:true,attrs:{\"class\":\"token punctuation\"}},[_vm._v(\"(\")]),_vm._v(\"morseArr\"),_c('span',{pre:true,attrs:{\"class\":\"token punctuation\"}},[_vm._v(\"[\")]),_vm._v(\"e\"),_c('span',{pre:true,attrs:{\"class\":\"token operator\"}},[_vm._v(\"-\")]),_c('span',{pre:true,attrs:{\"class\":\"token string\"}},[_vm._v(\"'a'\")]),_c('span',{pre:true,attrs:{\"class\":\"token punctuation\"}},[_vm._v(\"]\")]),_c('span',{pre:true,attrs:{\"class\":\"token punctuation\"}},[_vm._v(\")\")]),_c('span',{pre:true,attrs:{\"class\":\"token punctuation\"}},[_vm._v(\";\")]),_vm._v(\"\\n            \"),_c('span',{pre:true,attrs:{\"class\":\"token punctuation\"}},[_vm._v(\"}\")]),_vm._v(\"\\n            moreSet\"),_c('span',{pre:true,attrs:{\"class\":\"token punctuation\"}},[_vm._v(\".\")]),_c('span',{pre:true,attrs:{\"class\":\"token function\"}},[_vm._v(\"add\")]),_c('span',{pre:true,attrs:{\"class\":\"token punctuation\"}},[_vm._v(\"(\")]),_vm._v(\"sb\"),_c('span',{pre:true,attrs:{\"class\":\"token punctuation\"}},[_vm._v(\".\")]),_c('span',{pre:true,attrs:{\"class\":\"token function\"}},[_vm._v(\"toString\")]),_c('span',{pre:true,attrs:{\"class\":\"token punctuation\"}},[_vm._v(\"(\")]),_c('span',{pre:true,attrs:{\"class\":\"token punctuation\"}},[_vm._v(\")\")]),_c('span',{pre:true,attrs:{\"class\":\"token punctuation\"}},[_vm._v(\")\")]),_c('span',{pre:true,attrs:{\"class\":\"token punctuation\"}},[_vm._v(\";\")]),_vm._v(\"\\n        \"),_c('span',{pre:true,attrs:{\"class\":\"token punctuation\"}},[_vm._v(\"}\")]),_vm._v(\"\\n        \"),_c('span',{pre:true,attrs:{\"class\":\"token keyword\"}},[_vm._v(\"return\")]),_vm._v(\" moreSet\"),_c('span',{pre:true,attrs:{\"class\":\"token punctuation\"}},[_vm._v(\".\")]),_c('span',{pre:true,attrs:{\"class\":\"token function\"}},[_vm._v(\"size\")]),_c('span',{pre:true,attrs:{\"class\":\"token punctuation\"}},[_vm._v(\"(\")]),_c('span',{pre:true,attrs:{\"class\":\"token punctuation\"}},[_vm._v(\")\")]),_c('span',{pre:true,attrs:{\"class\":\"token punctuation\"}},[_vm._v(\";\")]),_vm._v(\"\\n    \"),_c('span',{pre:true,attrs:{\"class\":\"token punctuation\"}},[_vm._v(\"}\")]),_vm._v(\"\\n\"),_c('span',{pre:true,attrs:{\"class\":\"token punctuation\"}},[_vm._v(\"}\")]),_vm._v(\"\\n\")])])])}]\n\nexport { render, staticRenderFns }"]}