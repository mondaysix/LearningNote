{"remainingRequest":"G:\\code\\LearningNote\\node_modules\\vue-loader\\lib\\index.js??ref--1-1!G:\\code\\LearningNote\\node_modules\\vuepress\\lib\\webpack\\markdownLoader.js??ref--1-2!G:\\code\\LearningNote\\docs\\swtest\\test-gui.md?vue&type=template&id=7c2e0cca&","dependencies":[{"path":"G:\\code\\LearningNote\\docs\\swtest\\test-gui.md","mtime":1559394502945},{"path":"G:\\code\\LearningNote\\node_modules\\cache-loader\\dist\\cjs.js","mtime":499162500000},{"path":"G:\\code\\LearningNote\\node_modules\\vue-loader\\lib\\loaders\\templateLoader.js","mtime":499162500000},{"path":"G:\\code\\LearningNote\\node_modules\\cache-loader\\dist\\cjs.js","mtime":499162500000},{"path":"G:\\code\\LearningNote\\node_modules\\vue-loader\\lib\\index.js","mtime":499162500000},{"path":"G:\\code\\LearningNote\\node_modules\\vuepress\\lib\\webpack\\markdownLoader.js","mtime":499162500000}],"contextDependencies":[],"result":["\n<div class=\"content\"><h1 id=\"gui测试\"><a class=\"header-anchor\" href=\"#gui测试\" aria-hidden=\"true\">#</a> GUI测试</h1>\n<p>​\tGUI自动化测试稳定性，表现为同样的测试用例在同样的环境上，时而测试通过，时而测试失败，严重降低了GUI测试的可信性</p>\n<p><strong>GUI测试不稳定的因素</strong>：</p>\n<ol>\n<li>非预计的弹出对话框</li>\n<li>页面控件属性的细微变化</li>\n<li>被测系统的A/B测试</li>\n<li>随机的页面延迟造成控件识别失败</li>\n<li>测试数据问题</li>\n</ol>\n<blockquote>\n<p>非预计的弹出对话框，一般包含两种场景：</p>\n</blockquote>\n<ul>\n<li>GUI自动化测试用例执行过程中，操作系统弹出的非预计对话框，比如弹出杀毒软件更新请求、病毒报告、系统更新请求等等</li>\n<li>被测软件本身在非预期的时间弹出预期的对话框，比如在网站进行操作时，随机弹出用户调查对话框</li>\n</ul>\n<p>那么怎么解决呢，在手工测试时，会直接点击关闭对话框，然后再继续业务测试操作，对自动化脚本来说也是同样的道理，一般可以这样做：</p>\n<p>当自动化脚本发现控件无法正常定位时或者无法继续操作，GUI自动化框架自动进入“异常场景恢复测试”，GUI自动化框架依次检查各种可能出现的对话框，一旦确认了对话框的类型，立即执行预定义的操作，接着重试刚才执行到的失败步骤。这种方式只能处理已知可能会出现的对话框，对于新类型的对话框，只能通过自动化的方式尝试点击上面的按钮进行处理。每当发现一种潜在会弹出的对话框，就把它更新到“异常场景”库中</p>\n<blockquote>\n<p>页面控件属性的细微变化</p>\n</blockquote>\n<ul>\n<li>如果页面控件的属性发生了变化，也会导致测试脚本的定位元素失败</li>\n</ul>\n<p>比如控件的id发生了变化，一般可以这样处理：</p>\n<p>通过控件的类型缩小范围，属性值的关键字再进一步缩小范围，或者根据属性变化前后的相似度</p>\n<blockquote>\n<p>被测系统的A/B测试</p>\n</blockquote>\n<p>A/B测试，通常为web或者app的界面或者流程提供两种不同的版本，然后让用户随机访问其中的一个版本，并收集两个版本的用户体验数据和业务数据，最后分析评估出最好的版本用于正式发布</p>\n<p>A/B测试通常会发布到实际生产环境，所以会造成不稳定性，一般解决思路：</p>\n<p>在测试脚本内部对不同的被测版本做分支处理，脚本能区分a和b两个版本并作出相应的处理</p>\n<blockquote>\n<p>随机的页面延迟造成控件识别失败</p>\n</blockquote>\n<p>加入重试机制，当某一步GUI操作失败时，框架会自动发起重试，往往重试方式不是测试框架自带的功能，需要进行二次开发来实现</p>\n<blockquote>\n<p>测试数据问题</p>\n</blockquote>\n<p>测试用例所依赖的数据被其他用例修改了，或者在测试过程中发生错误后自动进行了重试操作，但数据状态已经在第一次执行中被修改了。</p>\n</div>\n",null]}